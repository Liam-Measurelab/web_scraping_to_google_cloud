{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web_scraping_to_gcloud.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMkQUY6oY+Qdnp4VfJONb5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liam-Measurelab/web_scraping_to_google_cloud/blob/main/web_scraping_to_gcloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPTw7VMo0cw5"
      },
      "source": [
        "# Preamble\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xtNIXym3Oav"
      },
      "source": [
        "I'm writing down a log of my activities on this project, but to better understand the learning taking place as well as documentation of the thought process behind the project. I hope that as I get progressively stronger with my python ability I will be able to come back to this project and see the development of both my mindset and techinical ability. Or perhaps I will laugh as my foolishness. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfEbkRzy1Cbc"
      },
      "source": [
        "# Project Reasoning and Scope \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYDf3oYh3AQx"
      },
      "source": [
        "## Project Reasoning \n",
        "In order to develop on my python, I believe that the fastest short cut is to create a usable colab with a clear function. I will aim for a MVP of the python and then possibly create more elegant code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjshRzc03HSB"
      },
      "source": [
        "## Project Scope \n",
        "I have been curious about webscraping for a while now and can see the value of having a database that log scrapped data daily. My goal is to develop python code that does the following:\n",
        "\n",
        "1. Scraps a website for certain data\n",
        "2. Manipulate the data with dataframes\n",
        "3. Push the dataframe to Google Cloud (Big Query or Cloud Storage) \n",
        "4. Add in ingestion date and repeat as partitioned table or seperate CSVs\n",
        "\n",
        "I am aiming to do this is fistly within a colab python doc and then possibly following with support moving the code into seperate functions to call in a bigger python script and then possibly hosting on Google Cloud Functions. \n",
        "\n",
        "Currently I am also only accessing public pages, however in future there is certainly scope to add a scope that allows for logging into certain pages or changing countries to see differences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3CLMAA04mZj"
      },
      "source": [
        "## 1. Web Scraping \n",
        "From my supportive reading there seems to be three different packages that support web scraping: \n",
        "1. For HTML and XML `requests` and `BeautifulSoup`.\n",
        "2. For Javascript `Selenium`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMWIKqyu-KwM"
      },
      "source": [
        "# Imports\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}